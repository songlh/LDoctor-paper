\section{Evaluation}
\label{sec:experiment}

\subsection{Methodology}
\label{sec:result_meth}
%Please discuss the potential usage scenarios of \Tool
%How you will use it together with other tools 


\begin{table}
  \centering
  \small
  \newcommand{\Yes}[1]{\checkmark{}$_#1$}
  \newcommand{\No}[0]{-}
  \begin{tabular}{lcccc}
    \toprule
   {\bf BugID}           &  {\bf KLOC}     &  {\bf P. L.}           & {\bf RootCause}  & {\bf Fix}\\
   \midrule
   Mozilla347306         & 88              & C                      &  0*1?        & C     \\
   Mozilla416628         & 105             & C                      &  0*1?        & C     \\
   Mozilla490742         &  -             & JS                     &  C-I         & B       \\
   Mozilla35294          &  -             & C++                    &  C-L         & B        \\ 
   Mozilla477564         &  -             & JS                     &  C-L         & M       \\
   \midrule 
   MySQL27287            & 995             & C++                    &  0*1?,C-L        & C     \\
   MySQL15811            & 1127            & C++                    &  C-L         & M \\ 
   \midrule    
   Apache32546           &  -             & Java                   &  C-I         & B  \\
   Apache37184           &  -             & Java                   &  C-I         & M  \\
   Apache29742           &  -             & Java                   &  C-L         & B \\ 
   Apache34464           &  -             & Java                   &  C-L         & M  \\
   Apache47223           &  -             & Java                   &  C-L         & B \\
   \midrule
   GCC46401              & 5521            & C                      &  [0$|$1]*    & S   \\
   GCC1687               & 2099            & C                      &  C-I         & M \\
   GCC27733              & 3217            & C                      &  C-I         & M \\
   GCC8805               & 2538            & C                      &  C-L         & B\\
   GCC21430              & 3844            & C                      &  C-L         & M \\
   GCC12322              & 2341            & C                      &  1*          & S\\
\bottomrule
   \end{tabular}
  %\nocaptionrule
  \caption{Benchmark information.
  (-: benchmarks extracted from real-world applications.
  ``C-I'': cross-iteration redundancy.
  ``C-L'': cross-loop redundancy.
  C, B, M, S: fix strategies as discussed in
  Table \ref{tab:root}.
  ) 
 }
  \label{tab:benchmarks}
\end{table}

\paragraph{Implementation and Platform}
We implement \Tool in LLVM-3.4.2 \cite{llvm}, and conduct our
%Our implementation consists of 17654 lines of C++ code, 
%with 4748 for instrumenter, 674 for resultless analysis, 
%5802 for redundancy analysis, 
%and the remaining 6430 for common utilities. 
experiments on a i7-960 machine, with Linux 3.11 kernel. 

\paragraph{Benchmarks}
We use 18 out of the 45 bugs listed in Table \ref{tab:root} as our 
evaluation benchmarks. Among these 18, seven are extracted from Java or JavaScript
programs and re-implemented in C++, as \Tool currently only handles C/C++
programs; one is extracted from a very old version of Mozilla.
%These 18 bugs include all the benchmarks used in the recent
%statistical performance debugging work~\cite{SongOOPSLA2014}.
The remaining bugs listed in Table \ref{tab:root} are much more difficult to
use as benchmarks, 
either because they depend on special hardware/software environment
or because they involve too complex data structures to extract. 
Overall, these 18 bugs cover a wide variety of performance root causes, as 
shown in Table~\ref{tab:benchmarks}. 

\paragraph{Metrics}
Our experiments are designed to evaluate \Tool from three main aspects:
(1) 
\textit{Coverage}. Given our benchmark suite that covers a wide variety
of real-world root causes, can \Tool identify all those root causes?
(2)
\textit{Accuracy}. 
When analyzing non-buggy loops, will \Tool generate any false positives?
(3) 
\textit{Performance}.
What is the run-time overhead of \Tool?

\paragraph{Evaluation settings}
Our evaluation uses existing statistical performance diagnosis
tool \cite{SongOOPSLA2014} to process a performance problem and identify 
one or a few suspicious loops for \Tool to analyze.
For 14 out of the 18 benchmarks, statistical debugging identifies the
real root-cause loop as the most suspicious loop. For the remaining
benchmarks, the real root-cause loops are ranked number 2, 2, 4, and 10.
%Overall, we believe future tools can accurately identify the most one or a couple
%of suspicious loops.

\begin{table}
  \centering
  \small
  \newcommand{\Yes}[0]{\checkmark}
  \newcommand{\No}[0]{-}
  \begin{tabular}{lcc}
    \toprule
                            	&  {\bf Reported}             &{\bf Fix }                     \\
   {\bf BugID}                  &  {\bf Root Cause}           &{\bf Suggestion}             \\
   \midrule
   Mozilla347306                & \Yes                        & \Yes                                          \\
   Mozilla416628                & \Yes                        & \Yes                                         \\
   Mozilla490742                & \Yes                        & \Yes                                             \\
   Mozilla35294                 & \Yes                          & \Yes                                              \\ 
   Mozilla477564                & \Yes                          & \Yes                                            \\
   \midrule 
   MySQL27287                   & \Yes                          & \ding{55}                                         \\
   MySQL15811                   & \Yes                          & \Yes                                      \\ 
   \midrule    
   Apache32546                  & \Yes                          & \Yes                                      \\
   Apache37184                  & \Yes                          & \Yes                                        \\
   Apache29742                  & \Yes                          & \Yes                                       \\ 
   Apache34464                  & \Yes                          & \Yes                                        \\
   Apache47223                  & \Yes                          & \Yes                                       \\
   \midrule
   GCC46401                     & \Yes                     & \Yes                                      \\
   GCC1687                      & \Yes                          & \Yes                                     \\
   GCC27733                     & \Yes                          & \Yes                                     \\
   GCC8805                      & \Yes                          & \Yes                                  \\
   GCC21430                     & \Yes                          & \Yes                                     \\
   GCC12322                     & \Yes                         & \ding{55}                                   \\
\bottomrule
   \end{tabular}
  %\nocaptionrule
  \caption{Coverage Results.}
  \label{tab:cover}
\end{table}


To evaluate the coverage, accuracy, and performance of \Tool, we mainly conduct
three sets of evaluation. First, we apply \Tool to the real root-cause loop to
see if \Tool can correctly identify the root-cause category and provide
correct fix-strategy suggestion. Second, we apply
statistical performance debugging \cite{SongOOPSLA2014} to all our benchmarks
and apply \Tool to the top 5 ranked loops\footnote{Some extracted benchmarks
have fewer than 5 loops. We simply apply \Tool to all loops in these cases.}
to see how accurate \Tool is. Third, we evaluate the run-time performance of
applying \Tool to the real root-cause loop. 
 
For all benchmarks we use, real-world
users have provided at least one problem-triggering input in their on-line 
bug bugs. We use these inputs in our run-time analysis.

As discussed in Section \ref{sec:design}, our analysis contains 
several configurable thresholds. In our evaluation,
we use 0.001 as the \textit{resultful rate} threshold for identifying
0*1? 
%loops, 0.01 as the \textit{resultful rate} threshold for identifying 
and [0$|$1]* resultless loops; we use 
0.5 as the \textit{redundancy rate} threshold for identifying redundant loops.
%, and 
%2 as the \textit{cross-iteration redundancy rate} (i.e., 
%the number of distinct iterations is less than half of the total iterations).

All the analysis and performance results presented below regarding
cross-loop analysis is obtained using $1/100$ sampling rate; all the
results regarding cross-iteration analysis is obtained using $1/1000$ sampling
rate. We use sparser sampling rate in the latter case, because there tend to
be more loop iterations than loop instances.
All our diagnosis results require only \textbf{one} run under the 
problem-triggering input.

More discussions about all the parameters/thresholds presented above, including
how to set them and how sensitive they are, are discussed in Section
\ref{sec:sensi}. 

\subsection{Coverage Results}
\label{sec:coverage}
Overall, \Tool provides good diagnosis coverage, as shown in Table~\ref{tab:cover}. 
\Tool identifies the correct root cause for \textbf{all} 18 benchmarks, and 
suggests fix strategies that exactly match what developers took in practice
for 16 out of 18 cases. There are only two cases where \Tool fails to suggest
the fix strategy that developers used. For MySQL\#27287, the root-cause loop
is both cross-loop redundant and 0*1? inefficient. \Tool suggests both changing
data structures and memoization as fix strategies. In practice, the developers
find a new data structure that can eliminate both root causes.
For GCC\#12322, \Tool correctly tells that the loop under study
does not contain any form of inefficiency and produce results in every 
iteration, and hence fails to suggest any fix strategy. In practice, GCC
developers decide to skip the loop, which will cause some programs compiled by
GCC
to be less performance-optimal than before. However, GCC developers feel
that it is worthwhile considering the slow-down caused by the original loop.

\subsection{Accuracy Results}
\label{sec:result_acc}

\begin{table}
  \centering
  \small
  \newcommand{\Yes}[0]{\checkmark}
  \newcommand{\No}[0]{-}
  \begin{tabular}{lcccccc}
    \toprule
   {\bf BugID}           &  {\bf 0*1?}          &  {\bf [0$|$1]*}             &{\bf C-I$_b$}            &{\bf C-I$_m$}          &   {\bf C-L}     & {\bf Total}  \\
   \midrule
   Mozilla347306         &   -                  & -                           & -                       & -                     &   -             & -\\
   Mozilla416628         &   -                  & -                           & -                       & -                     &   -             & -\\
   Mozilla490742        &   -                  & -                           & -                       & -                     &   -             & -\\
   Mozilla35294         &   -                  & -                           & -                       & -                     &   -             & -\\ 
   Mozilla477564         &   -                  & -                           & -                       & -                     &   -             & -\\
   \midrule 
   MySQL27287            &   -                  & 0$_1$                       & -                       & -                     &   -             & 0$_1$\\
   MySQL15811            &   -                  & -                           & -                       & -                     &   -             & -\\ 
   \midrule    
   Apache32546           &   -                  & -                           & -                       & -                     &   -             & -\\
   Apache37184           &   -                  & -                           & -                       & -                     &   -             & -\\
   Apache29742       &   -                  & -                           & -                       & -                     &   -             & -\\ 
   Apache34464           &   -                  & -                           & -                       & -                     &   -             & -\\
   Apache47223           &   -                  & -                           & -                       & -                     &   -             & -\\
   \midrule
   GCC46401              &   -                  & 0$_1$                       & -                       & -                     &   -             & 0$_1$\\
   GCC1687               &   -                  & -                           & -                       & -                     &   -             & -\\
   GCC27733            &   -                  & -                           & -                       & -                     &   -             & - \\
   GCC8805               &   -                  & 0$_1$                       & -                       & -                     &   -             & 0$_1$\\
   GCC21430              &   0$_1$              & 0$_3$                       & -                       & 0$_1$                 &   0$_1$         & 0$_6$\\
   GCC12322              &   0$_1$              & 0$_1$                       & -                       & 0$_1$                 &   0$_1$         & 0$_4$\\
\bottomrule
   \end{tabular}
  %\nocaptionrule
\vspace{-0.1in}
  \caption{False positives of \Tool for top 5 loops reported by 
    statistical debugging for each benchmark. `-': no false positive. $x_y$: real ($x$) and benign false positives ($y$).
}
  \label{tab:top5}
\end{table}

As shown in Table \ref{tab:top5}, \Tool is accurate, having 0 real
false positive and 14 benign false positives for all the top 5 loops.

Here, benign false positives mean that the \Tool analysis result is true ---
some loops are indeed cross-iteration/loop redundant or indeed producing
results in only a small portion of all the iterations. However, those
problems are \textit{not} fixed by developers in their performance patches. 

There are several reasons for these benign performance problems. 
The main reason is that they are not the main contributor to the 
performance problem perceived by the users. This happens to 11 out of the
13 benign cases. In fact, this is not really a problem for \Tool in 
real usage scenarios, because statistical debugging can accurately
tell that these loops are not top contributors to the performance
problems.
The remaining two cases happen when fixing the 
identified redundant/resultless problems
are very difficult and hence developers decide not to fix them.

The accuracy of \Tool benefits from its run-time analysis.
For example, there are 7 benchmarks in total that each contains
a loop that generates side effect only
in its last iteration. Without run-time information, \Tool would judge
all of them as inefficient (0*1? resultless). Fortunately,
\Tool run-time counts the total number of iterations and
correctly identifies 3 of them as truly inefficient and severe enough
to cause the corresponding performance problem.

\Tool can also help improve the accuracy of statistical debugging in
identifying which loop is the root-cause loop.
For example, the real root-cause loop of Apache\#34464 and GCC\#46401 both
rank number two by the statistical performance diagnosis tool.
Fortunately,
\Tool can tell that the number one loops in both cases do not contain
any form of inefficiency, resultless or redundancy. 

\subsection{Performance}
\label{sec:result_perf}

\begin{table}
  \centering
  \scriptsize
  \newcommand{\Yes}[1]{\checkmark{}$_#1$}
  \newcommand{\No}[0]{-}
  \begin{tabular}{lccccc}
    \toprule
	    & \multicolumn{3}{c}{\Tool w/ optimization} & \multicolumn{2}{c}{w/o optimization} \\
     \cmidrule(lr){2-4}
     \cmidrule(lr){5-6}
     {\bf BugID}  & {\bf Resultless}  &  {\bf C-L R. } & {\bf C-I R. }  & {\bf C-L R.}  & {\bf C-I R. } \\
    \midrule
    Mozilla347306 &  1.07\%           &  22.40\%       &  10.17\%       & 304.37{\bf X} & 468.74{\bf X} \\ 
    Mozilla416628 &  0.80\%           &  4.10\%        &  2.99\%        & 567.51{\bf X} & 85.6{\bf X} \\
    \midrule
     MySQL27287   & $\sim$0           &   1.66\%       &   -            & 109.55{\bf X} & 352.07{\bf X} \\
     MySQL15811   &  -                &   0.03\%       &   -            & 227.04{\bf X} & 424.44{\bf X} \\
    \midrule
      GCC46401    & 3.12\%         & 3.80\%            &  5.95\%        & 21.07{\bf X}  & 38.44{\bf X}\\ 
      GCC1687     & -              & /                 &  $\sim$0       &   /           & 142.29{\bf X} \\
      GCC27733    & $\sim$0        & /                 &  4.73\%        &   /           & 17.41{\bf X}     \\
      GCC8805     & -              & $\sim$0           & $\sim$0        & 2.22{\bf X}   &  3.52{\bf X}\\
      GCC21430    & -              & 5.46\%            &   0.69\%       & 107.20{\bf X} & 159.89{\bf X} \\
      GCC12322    & -              & 1.75\%            &  $\sim$0       & 21.07{\bf X}  & 38.44{\bf X} \\
   \bottomrule
   \end{tabular}
  %\nocaptionrule
  \caption{Run-time overhead of applying \Tool to the buggy loop
    (only non-extracted benchmarks are shown). 
  -: dynamic analysis is not needed;
  /: not applicable.}
  \label{tab:performance}
\end{table}


\comment{
\begin{table}
  \centering
  \scriptsize
  \newcommand{\Yes}[1]{\checkmark{}$_#1$}
  \newcommand{\No}[0]{-}
  \begin{tabular}{lccccc}
    \toprule
                       & {\bf Resultless} &  \multicolumn{2}{c}{\bf C-L R. } & \multicolumn{2}{c}{\bf C-I R.}\\
      \cmidrule(lr){3-4}    
      \cmidrule(lr){5-6}   
     {\bf BugID}       &                & Not               &  S.+O.            & Not                & S.+O.  \\
     \midrule
     Mozilla347306     & 1.07\%         & 303.37{\bf X}     &  22.40\%       & 467.74{\bf X}         & 10.17\%      \\
     Mozilla416628     & 0.80\%         & 56.51{\bf X}      &  4.10\%        & 84.6{\bf X}           & 2.99\%\\
     \midrule
     MySQL27287        & $\sim$0        & 108.55{\bf X}     &  1.66\%        & 351.07{\bf X}         & - \\
     MySQL15811        &  -             & 226.04{\bf X}     &  0.03\%        & 423.44{\bf X}         & - \\
     \midrule
      GCC46401         & 3.12\%         & 20.07{\bf X}      &  3.80\%        & 37.44{\bf X}          & 5.95\%\\ 
      GCC1687          & -              & /                 &  /             & 141.29{\bf X}         & $\sim$0 \\
      GCC27733         & $\sim$0        & /                 &  /             & 16.41{\bf X}          & 4.73\%         \\
      GCC8805          & -              & 1.22{\bf X}       & $\sim$0        & 2.52{\bf X}           & $\sim$0\\
      GCC21430         & -              & 106.20{\bf X}     & 5.46\%         & 158.89{\bf X}         & 0.69\%\\
      GCC12322         & -              & 20.07{\bf X}      & 1.75\%         & 37.44{\bf X}          & $\sim$0\\
  \bottomrule
   \end{tabular}
  %\nocaptionrule
  \caption{Run-time overhead of applying \Tool to the buggy loop. 
    Only performance results from non-extracted benchmarks are shown here. 
  Not: not applying the performance optimization in \Tool.
  -: static analysis can figure out the results and hence no dynamic analysis is conducted.
  /: not applicable. }
  \label{tab:performance}
\end{table}
}

As shown in Table \ref{tab:performance}, 
the performance of \Tool is good. The overhead is consistently under or around 5\% 
except for one benchmark, Mozilla\#347306. We believe \Tool is promising for potential production
run usage.
We can easily further lower the overhead through sparser sampling.
As we will discuss later, 
the current diagnosis results are obtained by running the
program only \textbf{once} under the problem-triggering workload.
If we use sparser sampling, more failure runs will be needed to obtain good
diagnosis results.

As we can also see from the table, our performance optimization discussed in 
Section \ref{sec:inst} and \ref{sec:perf} has helped.

The performance benefit of sampling is huge.
Without sampling, even with all the static optimization, redundancy
analysis lead to over 100X slowdown for five benchmarks.

The benefit of static optimization is also non-trivial. 
For example, for MySQL\#15811 and MySQL\#27287, static analysis alone can
judge that they do not contain cross-iteration redundancy: the computation of 
each iteration depends on loop induction variables, which are naturally different
in different iterations. Consequently, run-time overhead is completely
eliminated for these two benchmarks.
As another example, the buggy loops of MySQL\#27287 and MySQL\#15811 access 
arrays. 
After changing to tracking the initial and ending memory-access addresses
of the array, instead of the content of the whole array accesses,
the overhead is reduced from 11.77\% to 1.66\% for MySQL\#27287, 
and from 20.46\% to 0.03\% for MySQL\#15811 respectively 
(sampling is conducted consistently here). 

\subsection{Parameter Setting and Sensitivity}
\label{sec:sensi}
\paragraph{Sampling rates}
We have tried different sampling rates for redundancy analysis.
Intuitively, sparser sampling leads to lower overhead but worse diagnosis
results. Due to space constraints, we briefly summarize the results below.

When we lower the sampling rate from 1/100 to 1/1000 
in cross-loop redundancy analysis,
Mozilla\#347306 still incurs the largest overhead (0.49\%). 
The diagnosis results remain the same for all but
GCC\#8805 and GCC\#12322, where too few samples are available
to judge redundancy.

When we lower the sampling rate from 1/1000 to 1/10000
in cross-iteration redundancy analysis,
Mozilla\#347306 has the largest overhead (4.47\%). 
%In fact, Mozilla347306 is the only one whose overhead is larger than 2\%. 
The diagnosis results remain 
the same for all but GCC\#12322.
%If we increase the sampling rate to 1/100, we will 
%have two benchmarks whose overhead is larger than 30\%.

\paragraph{Resultful and redundancy rate}
Since the severity of resultless and redundant loops depends on
workload, it is natural that \Tool uses two thresholds in its diagnosis.
In fact, the diagnosis results are largely insensitive to the threshold
setting. For example, the results would remain the same when
changing the redundancy rate threshold from 0.5 to any value between about
0.1 and 0.7. We will have 1 more false negative and 1 fewer benign false positive, 
when the rate is 0.75. The trend is similar for resultless
loop checking. 

Our default setting %is obtained based on our experience
should work for many problems.
Developers can adjust these thresholds. 
They can even get rid of thresholds, and only
use the raw values of resultful/redundancy rates to understand
the absolute and relative (in)efficiency nature of suspicious 
loops. Based on our experiments, the difference between efficient and inefficient
loops is usually obvious, based on these rates.


